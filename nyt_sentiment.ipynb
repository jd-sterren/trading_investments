{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e3c0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting NYT Sentiment Fetcher...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\AppData\\Local\\Temp\\ipykernel_23548\\3129445278.py:81: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  sentiment_df = pd.concat([\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:43] âœ… Sentiment updated and saved.\n",
      "[19:50:46] âœ… Sentiment updated and saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from textblob import TextBlob  # Basic NLP Sentiment Analysis\n",
    "from inc.credential_manager import inject_decrypted_env\n",
    "import inc.functions as fn\n",
    "\n",
    "# Decrypt and inject environment variables\n",
    "inject_decrypted_env(environment=\"prod\", required_vars=[\"NYT_API_KEY\"])\n",
    "\n",
    "# Configuration\n",
    "NYT_API_KEY = os.getenv(\"NYT_API_KEY\")  # Set this in your environment!\n",
    "SAVE_FOLDER = \"data/sentiment/\"\n",
    "PULL_INTERVAL_MINUTES = 60\n",
    "SYMBOLS = {\n",
    "    \"AAPL\": \"Apple\",\n",
    "    \"TSLA\": \"Tesla\",\n",
    "    \"GOOG\": \"Google\",\n",
    "    \"MSFT\": \"Microsoft\"\n",
    "}\n",
    "NYT_SEARCH_URL = \"https://api.nytimes.com/svc/search/v2/articlesearch.json\"\n",
    "\n",
    "# Ensure save directory exists\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
    "\n",
    "# In-memory sentiment cache\n",
    "symbol_sentiment_cache = {}\n",
    "\n",
    "# Historical DataFrame\n",
    "sentiment_history_path = os.path.join(SAVE_FOLDER, \"nyt_sentiment_history.xlsx\")\n",
    "if os.path.exists(sentiment_history_path):\n",
    "    sentiment_df = pd.read_excel(sentiment_history_path)\n",
    "else:\n",
    "    sentiment_df = pd.DataFrame(columns=[\"timestamp\", \"symbol\", \"headline\", \"sentiment_score\"])\n",
    "\n",
    "\n",
    "def fetch_sentiment_for_symbol(symbol, search_term):\n",
    "    params = {\n",
    "        \"q\": search_term,\n",
    "        \"api-key\": NYT_API_KEY,\n",
    "        \"sort\": \"newest\",\n",
    "        \"page\": 0  # First page only for freshness\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(NYT_SEARCH_URL, params=params)\n",
    "        response.raise_for_status()\n",
    "        articles = response.json().get(\"response\", {}).get(\"docs\", [])\n",
    "\n",
    "        scores = []\n",
    "        headlines = []\n",
    "\n",
    "        for article in articles:\n",
    "            headline = article.get(\"headline\", {}).get(\"main\", \"\")\n",
    "            if not headline:\n",
    "                continue\n",
    "\n",
    "            # Sentiment analysis on headline\n",
    "            analysis = TextBlob(headline)\n",
    "            polarity = analysis.sentiment.polarity  # -1 to 1\n",
    "\n",
    "            scores.append(polarity)\n",
    "            headlines.append(headline)\n",
    "\n",
    "        if scores:\n",
    "            avg_score = sum(scores) / len(scores)\n",
    "        else:\n",
    "            avg_score = 0  # Neutral if no articles\n",
    "\n",
    "        # Update live cache\n",
    "        symbol_sentiment_cache[symbol] = {\n",
    "            \"sentiment\": avg_score,\n",
    "            \"timestamp\": datetime.now()\n",
    "        }\n",
    "\n",
    "        # Update historical dataframe\n",
    "        global sentiment_df\n",
    "        for article, score in zip(articles, scores):\n",
    "            hl = article.get(\"headline\", {}).get(\"main\", \"\")\n",
    "            pub_date = pd.to_datetime(article.get(\"pub_date\"))\n",
    "\n",
    "            sentiment_df = pd.concat([\n",
    "                sentiment_df,\n",
    "                pd.DataFrame.from_records([{\n",
    "                    \"timestamp\": pub_date,\n",
    "                    \"symbol\": symbol,\n",
    "                    \"headline\": hl,\n",
    "                    \"sentiment_score\": score\n",
    "                }])\n",
    "            ], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching sentiment for {symbol}: {e}\")\n",
    "\n",
    "\n",
    "def main_loop():\n",
    "    print(\"Starting NYT Sentiment Fetcher...\")\n",
    "    while True:\n",
    "        for symbol, search_term in SYMBOLS.items():\n",
    "            fetch_sentiment_for_symbol(symbol, search_term)\n",
    "\n",
    "        # Remove duplicates from historical DataFrame\n",
    "        sentiment_df.drop_duplicates(subset=[\"symbol\", \"headline\", \"timestamp\"], inplace=True)\n",
    "\n",
    "        # Save historical sentiment to Excel\n",
    "        sentiment_df.to_excel(sentiment_history_path, index=False)\n",
    "        print(f\"[{datetime.now().strftime('%H:%M:%S')}] Sentiment updated and saved.\")\n",
    "\n",
    "        # Sleep until next pull\n",
    "        time.sleep(PULL_INTERVAL_MINUTES * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_loop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gideon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
